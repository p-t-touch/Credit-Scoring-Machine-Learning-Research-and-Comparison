{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Data Profilling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.axes as ax\n",
    "import sklearn\n",
    "#print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read all the domcuments artribute types as required ###\n",
    "### Change File Location as needed ###\n",
    "CS_DS = pd.read_csv(\"C:/Users/USER/5. SCG/preML_v5b_010622.csv\",\n",
    "        dtype={\"tax_id\": str, \"cust_name\": str,\"mind_sect\": str, \"input1_tax_id\": str\n",
    "                            #\"max_overdue_days\": float,\n",
    "              })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CS_DS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Drop Columns that won't be used in machine learning algorithm ###\n",
    "CS_DS2 = CS_DS.drop(columns=['tax_id','cust_name','mind_sect','input1_tax_id','class_max'])\n",
    "CS_DS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>50%</th>\n",
       "      <th>max</th>\n",
       "      <th>non_zeros</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>max_overdue_days</th>\n",
       "      <td>max_overdue_days</td>\n",
       "      <td>1244.000000</td>\n",
       "      <td>49.299839</td>\n",
       "      <td>107.200728</td>\n",
       "      <td>-42.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>2242.000000</td>\n",
       "      <td>1132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_overdue_days</th>\n",
       "      <td>average_overdue_days</td>\n",
       "      <td>1244.000000</td>\n",
       "      <td>17.753079</td>\n",
       "      <td>75.354339</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>2232.200000</td>\n",
       "      <td>1111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overdue_payments</th>\n",
       "      <td>overdue_payments</td>\n",
       "      <td>1244.000000</td>\n",
       "      <td>96.551447</td>\n",
       "      <td>525.799406</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13366.000000</td>\n",
       "      <td>1111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_payments</th>\n",
       "      <td>total_payments</td>\n",
       "      <td>1244.000000</td>\n",
       "      <td>910.383441</td>\n",
       "      <td>2114.060288</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>150.500000</td>\n",
       "      <td>30352.000000</td>\n",
       "      <td>1244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>before_due_bucket</th>\n",
       "      <td>before_due_bucket</td>\n",
       "      <td>1244.000000</td>\n",
       "      <td>32.491961</td>\n",
       "      <td>189.192383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3466.000000</td>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OD_outstanding_std</th>\n",
       "      <td>OD_outstanding_std</td>\n",
       "      <td>1244.000000</td>\n",
       "      <td>1612062.842366</td>\n",
       "      <td>6341953.682936</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64454129.840000</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OD_utilize_max</th>\n",
       "      <td>OD_utilize_max</td>\n",
       "      <td>1244.000000</td>\n",
       "      <td>0.126141</td>\n",
       "      <td>0.300820</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.621627</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OD_utilize_mean</th>\n",
       "      <td>OD_utilize_mean</td>\n",
       "      <td>1244.000000</td>\n",
       "      <td>0.101097</td>\n",
       "      <td>0.256194</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.008004</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OD_utilize_std</th>\n",
       "      <td>OD_utilize_std</td>\n",
       "      <td>1244.000000</td>\n",
       "      <td>0.018720</td>\n",
       "      <td>0.058092</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.475033</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_max_binary</th>\n",
       "      <td>class_max_binary</td>\n",
       "      <td>1244.000000</td>\n",
       "      <td>0.524116</td>\n",
       "      <td>0.499619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Name       count           mean  \\\n",
       "max_overdue_days          max_overdue_days 1244.000000      49.299839   \n",
       "average_overdue_days  average_overdue_days 1244.000000      17.753079   \n",
       "overdue_payments          overdue_payments 1244.000000      96.551447   \n",
       "total_payments              total_payments 1244.000000     910.383441   \n",
       "before_due_bucket        before_due_bucket 1244.000000      32.491961   \n",
       "...                                    ...         ...            ...   \n",
       "OD_outstanding_std      OD_outstanding_std 1244.000000 1612062.842366   \n",
       "OD_utilize_max              OD_utilize_max 1244.000000       0.126141   \n",
       "OD_utilize_mean            OD_utilize_mean 1244.000000       0.101097   \n",
       "OD_utilize_std              OD_utilize_std 1244.000000       0.018720   \n",
       "class_max_binary          class_max_binary 1244.000000       0.524116   \n",
       "\n",
       "                                std        min        50%             max  \\\n",
       "max_overdue_days         107.200728 -42.000000  18.000000     2242.000000   \n",
       "average_overdue_days      75.354339   0.000000   5.600000     2232.200000   \n",
       "overdue_payments         525.799406   0.000000  11.000000    13366.000000   \n",
       "total_payments          2114.060288   1.000000 150.500000    30352.000000   \n",
       "before_due_bucket        189.192383   0.000000   1.000000     3466.000000   \n",
       "...                             ...        ...        ...             ...   \n",
       "OD_outstanding_std   6341953.682936   0.000000   0.000000 64454129.840000   \n",
       "OD_utilize_max             0.300820   0.000000   0.000000        1.621627   \n",
       "OD_utilize_mean            0.256194   0.000000   0.000000        1.008004   \n",
       "OD_utilize_std             0.058092   0.000000   0.000000        0.475033   \n",
       "class_max_binary           0.499619   0.000000   1.000000        1.000000   \n",
       "\n",
       "                      non_zeros  \n",
       "max_overdue_days           1132  \n",
       "average_overdue_days       1111  \n",
       "overdue_payments           1111  \n",
       "total_payments             1244  \n",
       "before_due_bucket           779  \n",
       "...                         ...  \n",
       "OD_outstanding_std          214  \n",
       "OD_utilize_max              238  \n",
       "OD_utilize_mean             238  \n",
       "OD_utilize_std              214  \n",
       "class_max_binary            652  \n",
       "\n",
       "[123 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Data Profile for Input Data ###\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('float_format', '{:f}'.format)\n",
    "describer = CS_DS2.describe(percentiles = [.5]).T\n",
    "list1 = np.count_nonzero(CS_DS2, axis=0).tolist()\n",
    "describer['non_zeros'] = list1\n",
    "describer['Name'] = describer.index\n",
    "\n",
    "describer = describer[['Name','count','mean','std','min','50%','max','non_zeros']]\n",
    "describer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cross-Validation [Stratified K-Fold] ###\n",
    "from statistics import mean, stdev\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "### Logistic Regression module ###\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "### Separate Data into inputs vs desired output\n",
    "#X = CS_DS2.iloc[:, 0:122].values\n",
    "#y = CS_DS2.iloc[:, 122].values\n",
    "X = CS_DS2.drop(['class_max_binary'], axis = 'columns').values #Train set\n",
    "y = CS_DS2.class_max_binary.values#Test set\n",
    "#X\n",
    "#y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Default Logistic Regression Settings\n",
    "log_reg = LogisticRegression(max_iter=100)\n",
    "### Default Random Forest Settings\n",
    "\n",
    "### USE PARAMETERS FROM RANDOMSEARCH HERE\n",
    "#LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "#          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "#          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
    "#          verbose=0, warm_start=False)\n",
    "\n",
    "### Split input and output into training and hidden(testing) data\n",
    "X_train, X_hidden, y_train, y_hidden = train_test_split(CS_DS2.drop(['class_max_binary'], axis = 'columns').values,\n",
    "                                                        CS_DS2.class_max_binary.values,\n",
    "                                                        stratify=y, test_size=0.15,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### StratifiedKFold - Cross validation\n",
    "- For making a good combination of both yes and no in the train set\n",
    "- Use stratisfied whenever we have a huge imbalance dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, balanced_accuracy_score\n",
    "\n",
    "### Manual stratified k-fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "\n",
    "lst_B_accu_stratified = []\n",
    "lst_accu_stratified = []\n",
    "\n",
    "for train_index, test_index in skf.split(X_train, y_train):\n",
    "    x_train_fold, x_test_fold = X_train[train_index], X_train[test_index]\n",
    "    y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n",
    "    \n",
    "    log_reg.fit(x_train_fold, y_train_fold) \n",
    "    #Without Kfold, will be  log_reg.fit(X_train, y_train)\n",
    "    y_pred_fold = log_reg.predict(x_test_fold)\n",
    "    \n",
    "    lst_accu_stratified.append(accuracy_score(y_test_fold, y_pred_fold))\n",
    "    lst_B_accu_stratified.append(balanced_accuracy_score(y_test_fold,y_pred_fold))\n",
    "    \n",
    "    #print(lst_B_accu_stratified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stratified K-fold evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Balanced Accuracy That can be obtained from this model is: 73.17857142857143 %\n",
      "\n",
      "Minimum Balanced Accuracy: 61.81818181818181 %\n",
      "\n",
      "Overall Balanced Accuracy: 68.38354341736694 %\n",
      "==================================\n",
      "Length Check\n",
      "full_data 1244 1244\n",
      "training 1057 1057\n",
      "Hidden 187 187\n",
      "folds train 952 952 test 105 105\n"
     ]
    }
   ],
   "source": [
    "### Cross-Validation Evaluation [Evaluated against validation sets not hidden set]     \n",
    "print('\\nMaximum Balanced Accuracy That can be obtained from this model is:',\n",
    "      max(lst_B_accu_stratified)*100, '%')\n",
    "print('\\nMinimum Balanced Accuracy:',\n",
    "      min(lst_B_accu_stratified)*100, '%')\n",
    "print('\\nOverall Balanced Accuracy:',\n",
    "      mean(lst_B_accu_stratified)*100, '%')\n",
    "print('==================================')\n",
    "print('Length Check')\n",
    "print('full_data',len(X),len(y))\n",
    "print('training',len(X_train),len(y_train))\n",
    "print('Hidden',len(X_hidden),len(y_hidden))\n",
    "print('folds','train',len(x_train_fold),len(y_train_fold),'test',len(x_test_fold),len(y_test_fold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Model Evaluations\n",
    "- Confusion matrix\n",
    "- accuracy score\n",
    "- ROC\n",
    "- Precision_Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== TRAINING ====\n",
      "[[316 187]\n",
      " [126 428]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.63      0.67       503\n",
      "           1       0.70      0.77      0.73       554\n",
      "\n",
      "    accuracy                           0.70      1057\n",
      "   macro avg       0.71      0.70      0.70      1057\n",
      "weighted avg       0.70      0.70      0.70      1057\n",
      "\n",
      "balanced accuracy: 0.7003968965987468\n",
      "\n",
      "==== HIDDEN ====\n",
      "\n",
      "[[50 39]\n",
      " [27 71]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.56      0.60        89\n",
      "           1       0.65      0.72      0.68        98\n",
      "\n",
      "    accuracy                           0.65       187\n",
      "   macro avg       0.65      0.64      0.64       187\n",
      "weighted avg       0.65      0.65      0.64       187\n",
      "\n",
      "Balanced Accuracy: 0.6431437743636781\n",
      "ROC AUC Score: 0.7244897959183673\n",
      "Average Precision Score: 0.7184658340396541\n"
     ]
    }
   ],
   "source": [
    "### Model Evaluation [Evaluated against Hidden Test Set / test set {Unseen Data}] ###\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, accuracy_score, balanced_accuracy_score)\n",
    "from sklearn.metrics import (roc_auc_score, plot_roc_curve, roc_curve, precision_recall_curve,plot_precision_recall_curve,average_precision_score, \n",
    "                             PrecisionRecallDisplay)\n",
    "\n",
    "y_pred_train = log_reg.predict(X_train)\n",
    "y_pred_hidden = log_reg.predict(X_hidden)\n",
    "\n",
    "print(\"==== TRAINING ====\")\n",
    "print(confusion_matrix(y_train,y_pred_train))\n",
    "print(classification_report(y_train,y_pred_train))\n",
    "print(\"balanced accuracy:\",balanced_accuracy_score(y_train,y_pred_train))\n",
    "\n",
    "print(\"\\n==== HIDDEN ====\\n\")\n",
    "print(confusion_matrix(y_hidden,y_pred_hidden))\n",
    "print(classification_report(y_hidden,y_pred_hidden))\n",
    "print(\"Balanced Accuracy:\",balanced_accuracy_score(y_hidden,y_pred_hidden))\n",
    "\n",
    "print(\"ROC AUC Score:\",roc_auc_score(y_hidden,log_reg.predict_proba(X_hidden)[:, 1]))\n",
    "\n",
    "print(\"Average Precision Score:\",average_precision_score(y_hidden,log_reg.predict_proba(X_hidden)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = CS_DS2.columns.tolist()\n",
    "\n",
    "feature_importance = pd.DataFrame(feature_names, columns = [\"feature\"])\n",
    "feature_importance[\"importance\"] = pow(math.e, w)\n",
    "feature_importance = feature_importance.sort_values(by = [\"importance\"], ascending=False)\n",
    " \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "ax = feature_importance.plot.barh(x='feature', y='importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Feature Importance Asessment [from Random Forest]\n",
    "feature_importance= log_reg.feature_importances_\n",
    "#feature_importance= grid_RF_test.feature_importances_\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + 0.5\n",
    "fig = plt.figure(figsize=(12, 20))\n",
    "feature_names = CS_DS2.columns.tolist()\n",
    "\n",
    "### Change plot settings as required ###\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.barh(pos, feature_importance[sorted_idx], align=\"center\")\n",
    "plt.yticks(pos, np.array(feature_names)[sorted_idx])\n",
    "plt.tick_params(axis='y', colors='white')\n",
    "plt.title(\"Feature Importance (MDI)\", color = 'white')\n",
    "#sorted_idx\n",
    "#feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.Hyper parameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': ['newton-cg', 'lbfgs', 'liblinear'], 'penalty': ['l2'], 'C': [100, 10, 1.0, 0.1, 0.01]}\n",
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:278: UserWarning: The total space of parameters 15 is smaller than n_iter=100. Running 15 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   13.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc \n",
      " {'solver': 'liblinear', 'penalty': 'l2', 'C': 100}\n",
      "ROC AUC Score: 0.7058014216922724\n",
      "ROC AUC Score: 0.7058014216922724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "#### HYPER PARAMETER SELECTION [Randomized CV Search] ####\n",
    "def param(score_type):\n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    \n",
    "    solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "    penalty = ['l2']\n",
    "    c_values = [100, 10, 1.0, 0.1, 0.01]\n",
    "    \n",
    "    # Create the random grid\n",
    "    random_grid = {'solver': solvers,\n",
    "                   'penalty': penalty,\n",
    "                   'C': c_values}\n",
    "    print(random_grid)\n",
    "\n",
    "    # Use the random grid to search for best hyperparameters\n",
    "    # First create the base model to tune\n",
    "    #RF_Model\n",
    "    # Random search of parameters, using 3 fold cross validation or change to desried k value, \n",
    "    # search across 100 different combinations, and use all available cores\n",
    "    log_reg_random = RandomizedSearchCV(estimator = log_reg, scoring =score_type, \n",
    "                param_distributions = random_grid, n_iter = 100, cv = 3, \n",
    "                verbose=2, random_state=42, n_jobs = -1)\n",
    "    # Fit the random search model\n",
    "    log_reg_random.fit(X_train, y_train)\n",
    "\n",
    "    print(score_type,\"\\n\",log_reg_random.best_params_)\n",
    "    best_random = log_reg_random.best_estimator_\n",
    "    print(\"ROC AUC Score:\",roc_auc_score(y_hidden,log_reg_random.predict_proba(X_hidden)[:, 1]))\n",
    "    print(\"ROC AUC Score:\",roc_auc_score(y_hidden,best_random.predict_proba(X_hidden)[:, 1]))\n",
    "\n",
    "#param('balanced_accuracy')\n",
    "param('roc_auc')\n",
    "#param('average_precision')\n",
    "\n",
    "### SEE IF ROC_AUC SCORE HAS IMPROVED OR NOT ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== TRAINING ====\n",
      "[[343 160]\n",
      " [118 436]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.68      0.71       503\n",
      "           1       0.73      0.79      0.76       554\n",
      "\n",
      "    accuracy                           0.74      1057\n",
      "   macro avg       0.74      0.73      0.73      1057\n",
      "weighted avg       0.74      0.74      0.74      1057\n",
      "\n",
      "balanced accuracy: 0.7344560794080284\n",
      "\n",
      "==== HIDDEN ====\n",
      "\n",
      "[[50 39]\n",
      " [29 69]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.56      0.60        89\n",
      "           1       0.64      0.70      0.67        98\n",
      "\n",
      "    accuracy                           0.64       187\n",
      "   macro avg       0.64      0.63      0.63       187\n",
      "weighted avg       0.64      0.64      0.63       187\n",
      "\n",
      "Balanced Accuracy: 0.632939692731025\n",
      "ROC AUC Score: 0.7058014216922724\n",
      "Average Precision Score: 0.6942823573762793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "### MODEL EVALUATION OF Settings from Randomized Search ###\n",
    "\n",
    "### USE PARAMETERS FROM RANDOMSEARCH HERE\n",
    "log_reg_model2 = LogisticRegression(solver = 'liblinear',\n",
    "                                    penalty = 'l2',\n",
    "                                    C = 100)\n",
    "\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, accuracy_score, \n",
    "                             balanced_accuracy_score)\n",
    "from sklearn.metrics import (roc_auc_score, plot_roc_curve, roc_curve, precision_recall_curve, \n",
    "                             plot_precision_recall_curve,average_precision_score, \n",
    "                             PrecisionRecallDisplay)\n",
    "\n",
    "log_reg_model2.fit(X_train, y_train)\n",
    "y_pred_train = log_reg_model2.predict(X_train)\n",
    "y_pred_hidden = log_reg_model2.predict(X_hidden)\n",
    "\n",
    "print(\"==== TRAINING ====\")\n",
    "print(confusion_matrix(y_train,y_pred_train))\n",
    "print(classification_report(y_train,y_pred_train))\n",
    "print(\"balanced accuracy:\",balanced_accuracy_score(y_train,y_pred_train))\n",
    "print(\"\\n==== HIDDEN ====\\n\")\n",
    "print(confusion_matrix(y_hidden,y_pred_hidden))\n",
    "print(classification_report(y_hidden,y_pred_hidden))\n",
    "print(\"Balanced Accuracy:\",balanced_accuracy_score(y_hidden,y_pred_hidden))\n",
    "print(\"ROC AUC Score:\",roc_auc_score(y_hidden,log_reg_model2.predict_proba(X_hidden)[:, 1]))\n",
    "print(\"Average Precision Score:\",average_precision_score(y_hidden,log_reg_model2.predict_proba(X_hidden)[:, 1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
